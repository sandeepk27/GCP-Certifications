{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79d42e5-3002-4036-8af5-12c7cc92693a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install -q --upgrade --user google-cloud-aiplatform==1.60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1491c262-c7d7-42ce-b610-0ce9f2bb50c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b386ee2-2260-4eda-b102-122a6353b582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-00-af66386a640e\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = ! gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "\n",
    "print(PROJECT_ID)\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04766f66-5a03-4e3f-8d5c-b6139d22d55f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594982df-49e3-4ca0-acc6-e72b358aa7da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_num(a, b):\n",
    "    print(\"Calling add function\")\n",
    "    return a+b\n",
    "def mul_num(a, b):\n",
    "    print(\"Calling multiply function\")\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083d8d9e-6894-4ef1-b156-1de38e21f83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function declaration for add_num\n",
    "add_num_func = FunctionDeclaration(\n",
    "    name=\"add_num\",\n",
    "    description=\"Add two numbers\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "# Function declaration for mul_num\n",
    "mul_num_func = FunctionDeclaration(\n",
    "    name=\"mul_num\",\n",
    "    description=\"Multiply two numbers\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n",
    "        },\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598db4bf-9807-42dd-9855-8aba0dabe6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a math Tool with add and multiply functions\n",
    "math_tool = Tool(\n",
    "    function_declarations=[add_num_func, mul_num_func],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d57c6b5-77b9-4a02-9fbd-a967124bc4db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the model with gemini-1.5-pro-001\n",
    "model = GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro-001\",\n",
    "    tools=[math_tool],  # Include the math tool\n",
    "    generation_config={\"temperature\": 0},  # Set temperature to 0\n",
    "    system_instruction=[\n",
    "        \"Fulfill the user's instructions.\",\n",
    "        \"If asked to add or multiply numbers, call the provided functions.\",\n",
    "        \"You may call one function after the other if needed.\",\n",
    "        \"Repeat the result to the user.\",\n",
    "        \"If there is a scenario of summing up of things and then multiplying use both the functions provided to get the best results\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86e14e57-7481-48f3-bfdd-995531f3b689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "792f0925-95b4-4689-a664-79f95b102606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_response(response):\n",
    "    # If there is a function call then invoke it\n",
    "    if response.candidates[0].function_calls:\n",
    "        function_call = response.candidates[0].function_calls[0]\n",
    "    else:\n",
    "        print(response.text)\n",
    "        return\n",
    "    \n",
    "    # Check if the function_call requests your add function\n",
    "    if function_call.name == \"add_num\":\n",
    "        # Extract the arguments to use in your function\n",
    "        a = function_call.args[\"a\"]\n",
    "        b = function_call.args[\"b\"]\n",
    "        # Call your function\n",
    "        result = add_num(a, b)\n",
    "        # Send the result back to the chat session with the model\n",
    "        response = model.generate_content(\n",
    "            Content(\n",
    "                role=\"user\",\n",
    "                parts=[Part.from_text(f\"The result of adding {a} and {b} is {result}.\")],\n",
    "            ),\n",
    "        )\n",
    "        # Make a recursive call of this handler function\n",
    "        handle_response(response)\n",
    "\n",
    "    # Check if the function_call requests your multiply function\n",
    "    elif function_call.name == \"mul_num\":\n",
    "        # Extract the arguments to use in your function\n",
    "        a = function_call.args[\"a\"]\n",
    "        b = function_call.args[\"b\"]\n",
    "        # Call your function\n",
    "        result = mul_num(a, b)\n",
    "        # Send the result back to the chat session with the model\n",
    "        response = model.generate_content(\n",
    "            Content(\n",
    "                role=\"user\",\n",
    "                parts=[Part.from_text(f\"The result of multiplying {a} and {b} is {result}.\")],\n",
    "            ),\n",
    "        )\n",
    "        # Make a recursive call of this handler function\n",
    "        handle_response(response)\n",
    "\n",
    "    else:\n",
    "        # You shouldn't end up here\n",
    "        print(function_call)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a2cd5d2-30c6-4a6d-9512-7f8e11ebb4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Tell me a joke.\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1459c1e6-4cbe-4319-b363-9c9ad5f96ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling multiply function\n",
      "You are right, the product of 7.0 and 16.0 is indeed 112.0. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"I have 7 pizzas each with 16 slices. How many slices do I have?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "270dede6-522e-41ac-884d-1aecd28c67a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "You are right, the result of adding 3.0 and 4.0 is indeed 7.0. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. How many pizzas did they bring together?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e58addf-2b59-43a4-aac3-3c117192d392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "You are right, the result of adding 3.0 and 4.0 is 7.0. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. There are 16 slices per pizza. How many slices are there?\")\n",
    "handle_response(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "150c3da0-db00-4585-8dab-0ac39a47fc42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "Calling add function\n",
      "You are right, the result of adding 4.0 and -2.0 is 2.0. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 4 pizzas, but Andrew dropped 2 on the ground. How many pizzas are left?\")\n",
    "handle_response(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6de6a3-c290-4870-8033-bee4a6d6ab05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
